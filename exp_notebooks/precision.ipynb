{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# List of all the data types in PyTorch\n",
    "data_types = [torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.complex32, torch.complex64, torch.complex128, torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8]\n",
    "\n",
    "# Create an empty dictionary to store the tensors\n",
    "tensors = {}\n",
    "forward_size = (64, 64, 128, 128)\n",
    "#forward_size = (64, 64, 32, 32)\n",
    "inverse_size = (64, 64, 128, 65)\n",
    "#inverse_size = (64, 64, 32, 17)\n",
    "\n",
    "for dtype in data_types:\n",
    "    if \"int\" in str(dtype):\n",
    "        # For integer types, we generate a tensor of random integers.\n",
    "        tensor = torch.randint(low=int(torch.iinfo(dtype).min), high=int(torch.iinfo(dtype).max), size=forward_size, dtype=dtype)\n",
    "    elif \"complex\" in str(dtype):\n",
    "        # For complex types, we generate a tensor of random complex numbers.\n",
    "        real = torch.randn(inverse_size, dtype=torch.get_default_dtype())\n",
    "        imag = torch.randn(inverse_size, dtype=torch.get_default_dtype())\n",
    "        tensor = torch.complex(real, imag)\n",
    "    else:\n",
    "        # For float types, we generate a tensor of random floats.\n",
    "        tensor = torch.randn(forward_size, dtype=dtype)\n",
    "\n",
    "    # Store the tensor in the dictionary\n",
    "    tensors[str(dtype)] = tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18774/2920195590.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensors['torch.complex128'] = torch.tensor(tensors['torch.complex64'].clone().detach(), dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "tensors['torch.complex32'] = tensors['torch.complex32'].chalf()\n",
    "tensors['torch.complex128'] = torch.tensor(tensors['torch.complex64'].clone().detach(), dtype=torch.complex128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time for torch.float16: 0.00838160514831543 seconds\n",
      "Processing time for torch.float32: 0.015894651412963867 seconds\n",
      "Processing time for torch.float64: 0.02886962890625 seconds\n",
      "Runtime error for torch.bfloat16: Unsupported dtype BFloat16\n",
      "Processing time for torch.complex32: 0.02862715721130371 seconds\n",
      "Processing time for torch.complex64: 0.01764655113220215 seconds\n",
      "Processing time for torch.complex128: 0.11345648765563965 seconds\n",
      "Processing time for torch.int8: 0.017026901245117188 seconds\n",
      "Processing time for torch.int16: 0.008291006088256836 seconds\n",
      "Processing time for torch.int32: 0.053975820541381836 seconds\n",
      "Processing time for torch.int64: 0.10680198669433594 seconds\n",
      "Processing time for torch.uint8: 0.015661954879760742 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processed_tensors = {}\n",
    "fft_dims = (2, 3)\n",
    "norm='backward'\n",
    "\n",
    "for dtype, tensor in tensors.items():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        tensor = tensor.to('cuda')\n",
    "\n",
    "        if \"complex\" in dtype:\n",
    "            # Apply irfftn to complex tensors\n",
    "            processed_tensors[dtype] = torch.fft.irfftn(tensor, dim=fft_dims, norm=norm)\n",
    "        elif \"float\" in dtype or \"bfloat\" in dtype:\n",
    "            # Apply rfftn to real (floating point) tensors\n",
    "            processed_tensors[dtype] = torch.fft.rfftn(tensor, dim=fft_dims, norm=norm)\n",
    "        \n",
    "        else:\n",
    "            # Apply fftn to integer tensors\n",
    "            processed_tensors[dtype] = torch.fft.rfftn(tensor,  dim=fft_dims, norm=norm)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"Processing time for {dtype}: {end_time - start_time} seconds\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Runtime error for {dtype}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 128, 65])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.full((64, 64, 128, 128), 10, dtype=torch.int32)\n",
    "test_tensor = test_tensor.to('cuda')\n",
    "test_fft = torch.fft.rfftn(test_tensor, dim=(2, 3), norm='backward')\n",
    "check_nan(test_fft)\n",
    "test_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nans in tensor\n",
    "def check_nan(tensor):\n",
    "    return torch.isnan(tensor).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.float16\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.float32\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.float64\n",
      "torch.Size([64, 64, 128, 128])\n",
      "No NaNs found in torch.complex32\n",
      "torch.Size([64, 64, 128, 128])\n",
      "No NaNs found in torch.complex64\n",
      "torch.Size([64, 64, 128, 128])\n",
      "No NaNs found in torch.complex128\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.int8\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.int16\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.int32\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.int64\n",
      "torch.Size([64, 64, 128, 65])\n",
      "No NaNs found in torch.uint8\n"
     ]
    }
   ],
   "source": [
    "for dtype, tensor in processed_tensors.items():\n",
    "    print(tensor.shape)\n",
    "    if check_nan(tensor):\n",
    "        print(f\"NaNs found in {dtype}\")\n",
    "    else:\n",
    "        print(f\"No NaNs found in {dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def einsum_complexhalf_two_input(eq, a, b):\n",
    "    \"\"\"\n",
    "    Return the einsum(eq, a, b)\n",
    "    We call this instead of standard einsum when either a or b is ComplexHalf,\n",
    "    to run the operation with half precision.\n",
    "    \"\"\"\n",
    "    assert len(eq.split(',')) == 2, \"Einsum equation must have two inputs\"\n",
    "\n",
    "    # cast both tensors to real and half precision\n",
    "    a = torch.view_as_real(a)\n",
    "    b = torch.view_as_real(b)\n",
    "    a = a.half()\n",
    "    b = b.half()\n",
    "\n",
    "    # create a new einsum equation \n",
    "    input_output = eq.split('->')\n",
    "    new_output = 'xy' + input_output[1]\n",
    "    input_terms = input_output[0].split(',')\n",
    "    new_inputs = [input_terms[0] + 'x', input_terms[1] + 'y']\n",
    "    new_eqn = new_inputs[0] + ',' + new_inputs[1] + '->' + new_output\n",
    "\n",
    "    tmp = torch.einsum(new_eqn, a, b)\n",
    "    res = torch.stack([tmp[0, 0, ...] - tmp[1, 1, ...], tmp[1, 0, ...] + tmp[0, 1, ...]], dim=-1)\n",
    "    return torch.view_as_complex(res)\n",
    "\n",
    "def einsum_complexhalf(eq, *args):\n",
    "    \"\"\"Compute einsum for complexhalf tensors\"\"\"\n",
    "\n",
    "    if len(args) == 2:\n",
    "        return einsum_complexhalf_two_input(eq, *args)\n",
    "\n",
    "    # todo: this can be made general. Call opt_einsum to get the partial_eqns\n",
    "    assert eq == 'abcd,e,be,fe,ce,de->afcd', \"Currently only implemented for this eqn\"\n",
    "\n",
    "    partial_eqns = ['fe,e->fe',\n",
    "                    'de,be->deb',\n",
    "                    'fe,ce->fec',\n",
    "                    'fec,deb->fcdb',\n",
    "                    'fcdb,abcd->afcd']\n",
    "\n",
    "    tensors = {}\n",
    "    labels = eq.split('->')[0].split(',')\n",
    "    tensors = dict(zip(labels,args))\n",
    "\n",
    "    for partial_eq in partial_eqns:\n",
    "        in_labels, out_label = partial_eq.split('->')\n",
    "        in_labels = in_labels.split(',')\n",
    "\n",
    "        in_tensors = [tensors[label] for label in in_labels]\n",
    "        result = einsum_complexhalf_two_input(partial_eq, *in_tensors)\n",
    "        tensors[out_label] = result\n",
    "\n",
    "    return tensors['afcd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import itertools\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.plugins import use_opt_einsum\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "use_opt_einsum('optimal')\n",
    "\n",
    "from tltorch.factorized_tensors.core import FactorizedTensor\n",
    "\n",
    "einsum_symbols = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "def _contract_dense(x, weight, separable=False):\n",
    "    order = tl.ndim(x)\n",
    "    # batch-size, in_channels, x, y...\n",
    "    x_syms = list(einsum_symbols[:order])\n",
    "\n",
    "    # in_channels, out_channels, x, y...\n",
    "    weight_syms = list(x_syms[1:]) # no batch-size\n",
    "\n",
    "    # batch-size, out_channels, x, y...\n",
    "    if separable:\n",
    "        out_syms = [x_syms[0]] + list(weight_syms)\n",
    "    else:\n",
    "        weight_syms.insert(1, einsum_symbols[order]) # outputs\n",
    "        out_syms = list(weight_syms)\n",
    "        out_syms[0] = x_syms[0] \n",
    "\n",
    "    eq= ''.join(x_syms) + ',' + ''.join(weight_syms) + '->' + ''.join(out_syms)\n",
    "\n",
    "    if not torch.is_tensor(weight):\n",
    "        weight = weight.to_tensor()\n",
    "\n",
    "    if x.dtype == torch.complex32:\n",
    "        return einsum_complexhalf(eq, x, weight)\n",
    "    else:\n",
    "        return tl.einsum(eq, x, weight)\n",
    "\n",
    "def _contract_dense_separable(x, weight, separable=True):\n",
    "    if separable == False:\n",
    "        raise ValueError('This function is only for separable=True')\n",
    "    return x*weight\n",
    "\n",
    "def _contract_cp(x, cp_weight, separable=False):\n",
    "    order = tl.ndim(x)\n",
    "\n",
    "    x_syms = str(einsum_symbols[:order])\n",
    "    rank_sym = einsum_symbols[order]\n",
    "    out_sym = einsum_symbols[order+1]\n",
    "    out_syms = list(x_syms)\n",
    "    if separable:\n",
    "        factor_syms = [einsum_symbols[1]+rank_sym] #in only\n",
    "    else:\n",
    "        out_syms[1] = out_sym\n",
    "        factor_syms = [einsum_symbols[1]+rank_sym,out_sym+rank_sym] #in, out\n",
    "    factor_syms += [xs+rank_sym for xs in x_syms[2:]] #x, y, ...\n",
    "    eq = x_syms + ',' + rank_sym + ',' + ','.join(factor_syms) + '->' + ''.join(out_syms)\n",
    "\n",
    "    if x.dtype == torch.complex32:\n",
    "        return einsum_complexhalf(eq, x, cp_weight.weights, *cp_weight.factors)\n",
    "    else:\n",
    "        return tl.einsum(eq, x, cp_weight.weights, *cp_weight.factors)\n",
    " \n",
    "\n",
    "def _contract_tucker(x, tucker_weight, separable=False):\n",
    "    order = tl.ndim(x)\n",
    "\n",
    "    x_syms = str(einsum_symbols[:order])\n",
    "    out_sym = einsum_symbols[order]\n",
    "    out_syms = list(x_syms)\n",
    "    if separable:\n",
    "        core_syms = einsum_symbols[order+1:2*order]\n",
    "        # factor_syms = [einsum_symbols[1]+core_syms[0]] #in only\n",
    "        factor_syms = [xs+rs for (xs, rs) in zip(x_syms[1:], core_syms)] #x, y, ...\n",
    "\n",
    "    else:\n",
    "        core_syms = einsum_symbols[order+1:2*order+1]\n",
    "        out_syms[1] = out_sym\n",
    "        factor_syms = [einsum_symbols[1]+core_syms[0], out_sym+core_syms[1]] #out, in\n",
    "        factor_syms += [xs+rs for (xs, rs) in zip(x_syms[2:], core_syms[2:])] #x, y, ...\n",
    "    \n",
    "    eq = x_syms + ',' + core_syms + ',' + ','.join(factor_syms) + '->' + ''.join(out_syms)\n",
    "\n",
    "    return tl.einsum(eq, x, tucker_weight.core, *tucker_weight.factors)\n",
    "\n",
    "\n",
    "def _contract_tt(x, tt_weight, separable=False):\n",
    "    order = tl.ndim(x)\n",
    "\n",
    "    x_syms = list(einsum_symbols[:order])\n",
    "    weight_syms = list(x_syms[1:]) # no batch-size\n",
    "    if not separable:\n",
    "        weight_syms.insert(1, einsum_symbols[order]) # outputs\n",
    "        out_syms = list(weight_syms)\n",
    "        out_syms[0] = x_syms[0]\n",
    "    else:\n",
    "        out_syms = list(x_syms)\n",
    "    rank_syms = list(einsum_symbols[order+1:])\n",
    "    tt_syms = []\n",
    "    for i, s in enumerate(weight_syms):\n",
    "        tt_syms.append([rank_syms[i], s, rank_syms[i+1]])\n",
    "    eq = ''.join(x_syms) + ',' + ','.join(''.join(f) for f in tt_syms) + '->' + ''.join(out_syms)\n",
    "\n",
    "    return tl.einsum(eq, x, *tt_weight.factors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseTensor(shape=torch.Size([64, 64, 32, 32]), rank=None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_shape = (64, 64, 32, 32)\n",
    "rank=1092\n",
    "factorization = 'cp'\n",
    "fixed_rank_modes = False\n",
    "decomposition_kwargs={}\n",
    "\n",
    "fac_weights = FactorizedTensor.new(\n",
    "                    weight_shape,\n",
    "                    rank=rank, #int(self.rank / 1.3**((2*n_layers-1-i)//2)), \n",
    "                    factorization=factorization, \n",
    "                    fixed_rank_modes=fixed_rank_modes,\n",
    "                    dtype=torch.complex64,\n",
    "                    **decomposition_kwargs\n",
    "                    ) \n",
    "fac_weights.normal_(0, 1)\n",
    "\n",
    "reg_weights = FactorizedTensor.new(\n",
    "                    weight_shape,\n",
    "                    rank=rank, #int(self.rank / 1.3**((2*n_layers-1-i)//2)), \n",
    "                    factorization=None, \n",
    "                    fixed_rank_modes=fixed_rank_modes,\n",
    "                    dtype=torch.complex64,\n",
    "                    **decomposition_kwargs\n",
    "                    ) \n",
    "reg_weights.normal_(0, 1)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = _contract_cp\n",
    "complex_size = (64, 64, 32, 32)\n",
    "#initialize complex tensors \n",
    "complex_tensors = {}\n",
    "real = torch.randn(complex_size, dtype=torch.get_default_dtype())\n",
    "imag = torch.randn(complex_size, dtype=torch.get_default_dtype())\n",
    "complex_tensors['complex64'] = torch.complex(real, imag)\n",
    "complex_tensors['complex32'] = complex_tensors['complex64'].chalf()\n",
    "#complex_tensors['complex128'] = torch.tensor(complex_tensors['complex64'].clone().detach(), dtype=torch.complex128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex64 time: 0.0398406982421875\n",
      "complex32 time: 0.1131296157836914\n"
     ]
    }
   ],
   "source": [
    "for dtype, tensor in complex_tensors.items():\n",
    "    tensor = tensor.cuda()\n",
    "    fac_weights = fac_weights.cuda()\n",
    "    start_time = time.time()\n",
    "    for i in range(100):\n",
    "        contract(tensor, fac_weights, separable=False)\n",
    "    end_time = time.time()\n",
    "    print(f'{dtype} time: {end_time-start_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.complex64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_tensors['complex32'].cfloat().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('low-precision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10b5bce8dd618bfd87d926b55929db2f91effada832fce0a722598fb6681704"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
